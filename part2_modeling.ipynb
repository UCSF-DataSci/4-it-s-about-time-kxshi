{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Time Series Modeling\n",
    "\n",
    "In this notebook, you will implement functions to extract features from time series data and build ARIMA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction\n",
    "\n",
    "Implement the `extract_time_series_features` function to calculate rolling window features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_series_features(data, window_size=60):\n",
    "    \"\"\"Extract rolling window features from time series data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Preprocessed physiological data\n",
    "    window_size : int\n",
    "        Size of the rolling window in seconds\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results : pd.DataFrame\n",
    "        DataFrame containing extracted features for each signal\n",
    "    \"\"\"\n",
    "    # 1. Calculate rolling window statistics\n",
    "    # 2. Include mean, std, min, max, and autocorrelation\n",
    "    data = data.copy()\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "    # Set timestamp as index for time-based rolling\n",
    "    data = data.set_index('timestamp')\n",
    "\n",
    "    # Function to compute autocorrelation using the pd Series.autocorr()\n",
    "    def autocorr(x, lag=1):\n",
    "        if len(x) <= lag:\n",
    "            return np.nan\n",
    "        return x.autocorr(lag=lag)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    # Group by subject and session\n",
    "    grouped = data.groupby(['subject_id', 'session'])\n",
    "\n",
    "    # because I sampled 4 Hz\n",
    "    window_size = 4 * window_size\n",
    "\n",
    "    for (subject, session), group in grouped:\n",
    "        # Apply rolling window\n",
    "        rolling = group[['eda', 'heart_rate', 'temperature']].rolling(f'{window_size}s')\n",
    "\n",
    "        # Compute features\n",
    "        stats = pd.DataFrame({\n",
    "            'eda_mean': rolling['eda'].mean(),\n",
    "            'eda_std': rolling['eda'].std(),\n",
    "            'eda_min': rolling['eda'].min(),\n",
    "            'eda_max': rolling['eda'].max(),\n",
    "            'eda_autocorr': rolling['eda'].apply(lambda x: autocorr(x), raw=False),\n",
    "            'heart_rate_mean': rolling['heart_rate'].mean(),\n",
    "            'heart_rate_std': rolling['heart_rate'].std(),\n",
    "            'heart_rate_min': rolling['heart_rate'].min(),\n",
    "            'heart_rate_max': rolling['heart_rate'].max(),\n",
    "            'heart_rate_autocorr': rolling['heart_rate'].apply(lambda x: autocorr(x), raw=False),\n",
    "            'temperature_mean': rolling['temperature'].mean(),\n",
    "            'temperature_std': rolling['temperature'].std(),\n",
    "            'temperature_min': rolling['temperature'].min(),\n",
    "            'temperature_max': rolling['temperature'].max(),\n",
    "            'temperature_autocorr': rolling['temperature'].apply(lambda x: autocorr(x), raw=False),\n",
    "        })\n",
    "\n",
    "        # Restore identifiers\n",
    "        stats['subject_id'] = subject\n",
    "        stats['session'] = session\n",
    "\n",
    "        features.append(stats)\n",
    "\n",
    "    result = pd.concat(features).reset_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp       eda  heart_rate  temperature subject_id  \\\n",
      "0  2018-12-05 16:29:07.000  0.024345  116.000000        21.91         S1   \n",
      "1  2018-12-05 16:29:07.250  0.023064  107.625004        21.91         S1   \n",
      "2  2018-12-05 16:29:07.500  0.024345   99.250000        21.91         S1   \n",
      "3  2018-12-05 16:29:07.750  0.023064   90.874996        21.91         S1   \n",
      "4  2018-12-05 16:29:08.000  0.023064   82.500000        21.93         S1   \n",
      "\n",
      "  session  \n",
      "0   Final  \n",
      "1   Final  \n",
      "2   Final  \n",
      "3   Final  \n",
      "4   Final  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevxs\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp  eda_mean   eda_std   eda_min   eda_max  \\\n",
      "0 2018-12-05 16:29:07.000  0.024345       NaN  0.024345  0.024345   \n",
      "1 2018-12-05 16:29:07.250  0.023704  0.000906  0.023064  0.024345   \n",
      "2 2018-12-05 16:29:07.500  0.023918  0.000740  0.023064  0.024345   \n",
      "3 2018-12-05 16:29:07.750  0.023704  0.000740  0.023064  0.024345   \n",
      "4 2018-12-05 16:29:08.000  0.023576  0.000702  0.023064  0.024345   \n",
      "5 2018-12-05 16:29:08.250  0.023491  0.000662  0.023064  0.024345   \n",
      "6 2018-12-05 16:29:08.500  0.023613  0.000685  0.023064  0.024345   \n",
      "7 2018-12-05 16:29:08.750  0.023544  0.000663  0.023064  0.024345   \n",
      "8 2018-12-05 16:29:09.000  0.023491  0.000640  0.023064  0.024345   \n",
      "9 2018-12-05 16:29:09.250  0.023320  0.000810  0.021783  0.024345   \n",
      "\n",
      "   eda_autocorr  heart_rate_mean  heart_rate_std  heart_rate_min  \\\n",
      "0           NaN       116.000000             NaN      116.000000   \n",
      "1           NaN       111.812502        5.922016      107.625004   \n",
      "2     -1.000000       107.625001        8.375000       99.250000   \n",
      "3     -1.000000       103.437500       10.812081       90.874996   \n",
      "4     -0.577350        99.250000       13.242039       82.500000   \n",
      "5     -0.408248        97.034583       13.028036       82.500000   \n",
      "6     -0.500000        95.946071       12.236643       82.500000   \n",
      "7     -0.547723        95.561875       11.380928       82.500000   \n",
      "8     -0.447214        95.647222       10.648961       82.500000   \n",
      "9     -0.138675        95.463500       10.056733       82.500000   \n",
      "\n",
      "   heart_rate_max  heart_rate_autocorr  temperature_mean  temperature_std  \\\n",
      "0           116.0                  NaN         21.910000              NaN   \n",
      "1           116.0                  NaN         21.910000         0.000000   \n",
      "2           116.0             1.000000         21.910000         0.000000   \n",
      "3           116.0             1.000000         21.910000         0.000000   \n",
      "4           116.0             1.000000         21.914000         0.008944   \n",
      "5           116.0             0.930434         21.916667         0.010328   \n",
      "6           116.0             0.903996         21.918571         0.010690   \n",
      "7           116.0             0.875713         21.920000         0.010690   \n",
      "8           116.0             0.844193         21.921111         0.010541   \n",
      "9           116.0             0.844287         21.922000         0.010328   \n",
      "\n",
      "   temperature_min  temperature_max  temperature_autocorr subject_id session  \n",
      "0            21.91            21.91                   NaN         S1   Final  \n",
      "1            21.91            21.91                   NaN         S1   Final  \n",
      "2            21.91            21.91                   NaN         S1   Final  \n",
      "3            21.91            21.91                   NaN         S1   Final  \n",
      "4            21.91            21.93                   NaN         S1   Final  \n",
      "5            21.91            21.93              0.612372         S1   Final  \n",
      "6            21.91            21.93              0.707107         S1   Final  \n",
      "7            21.91            21.93              0.750000         S1   Final  \n",
      "8            21.91            21.93              0.774597         S1   Final  \n",
      "9            21.91            21.93              0.790569         S1   Final  \n"
     ]
    }
   ],
   "source": [
    "def load_subject_data(subject_id, base_dir='data/processed'):\n",
    "    filename = f\"{subject_id}.csv\"  # e.g., S1.csv\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"No file found for subject {subject_id} at {file_path}\")\n",
    "    \n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "data_dir = 'data/processed'\n",
    "raw_data_path = os.path.join(os.getcwd(), data_dir)\n",
    "\n",
    "df_s1 = load_subject_data(\"S1\")\n",
    "print(df_s1.head())\n",
    "\n",
    "df_s1_cut = df_s1.head(5000)\n",
    "\n",
    "rolling = extract_time_series_features(df_s1_cut, window_size=60)\n",
    "print(rolling.head(10))\n",
    "\n",
    "# gets some warnings when the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARIMA Modeling\n",
    "\n",
    "Implement the `build_arima_model` function to fit ARIMA models and generate diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arima_model(series, order=(1,1,1), output_dir='plots'):\n",
    "    \"\"\"Fit an ARIMA model to the time series and generate diagnostic plots.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Time series data to model\n",
    "    order : tuple\n",
    "        (p,d,q) order of the ARIMA model\n",
    "    output_dir : str\n",
    "        Directory to save diagnostic plots\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model_fit: statsmodels.tsa.arima.model.ARIMAResults\n",
    "        Fitted ARIMA model\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # note that in this project we don't actually separate out things by session, so naively throwing in a \"series\" from previous functions will probably mix \"final\" and \"midterms\" data\n",
    "    \n",
    "    # Your code here\n",
    "    # 1. Fit ARIMA model\n",
    "\n",
    "    # Step 1: Check for stationarity using Augmented Dickey-Fuller test\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"ADF Statistic: {result[0]:.4f}\")\n",
    "    print(f\"p-value: {result[1]:.4f}\")\n",
    "    if result[1] > 0.05:\n",
    "        print(\"Warning: Series appears non-stationary (p > 0.05).\")\n",
    "\n",
    "    series = series.reset_index(drop=True) # since the series isn't including timestamp data\n",
    "\n",
    "    # Step 2: Fit ARIMA model\n",
    "    model = ARIMA(series, order=order) # not actually sure what the best order to choose is - can maybe run ADF test afterwards, but we actually set the order as an argument so just use the set order regardless\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Step 3: Plot model fit\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(series, label='Original')\n",
    "    plt.plot(model_fit.fittedvalues, label='Fitted', color='orange')\n",
    "    plt.title('ARIMA Model Fit')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'arima_fit.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Step 4: Plot residuals\n",
    "    residuals = model_fit.resid\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    ax[0].plot(residuals)\n",
    "    ax[0].set_title('Residuals')\n",
    "    ax[1].hist(residuals, bins=30)\n",
    "    ax[1].set_title('Residual Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'arima_residuals.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Step 5: Forecast plot\n",
    "    forecast_steps = 50\n",
    "    forecast = model_fit.get_forecast(steps=forecast_steps)\n",
    "    # forecast_index = pd.date_range(start=series.index[-1], periods=forecast_steps + 1, freq='250ms')[1:]\n",
    "    forecast_index = range(len(series), len(series) + forecast_steps)\n",
    "    forecast_series = pd.Series(forecast.predicted_mean.values, index=forecast_index)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(series, label='Original')\n",
    "    plt.plot(forecast_series, label='Forecast', color='orange')\n",
    "    plt.title('ARIMA Forecast')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'arima_forecast.png'))\n",
    "    plt.close()\n",
    "\n",
    "    return model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.3962\n",
      "p-value: 0.5841\n",
      "Warning: Series appears non-stationary (p > 0.05).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x150d609b460>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_arima_model(df_s1.head(10000)['eda'], order=(1,1,1), output_dir='plots/S1_eda_arima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
